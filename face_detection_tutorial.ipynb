{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29120e4",
   "metadata": {},
   "source": [
    "# 🤖 얼굴 감지 및 감정 인식 튜토리얼\n",
    "\n",
    "안녕하세요! 이 튜토리얼에서는 **AI를 이용해서 웹캠으로 얼굴을 감지하고 감정을 인식**하는 프로그램을 만들어보겠습니다.\n",
    "\n",
    "## 🎯 무엇을 배울까요?\n",
    "- YOLO AI 모델을 사용해서 사람을 감지하는 방법\n",
    "- dlib 라이브러리로 얼굴의 정확한 외곽선을 그리는 방법\n",
    "- 얼굴 표정을 분석해서 감정을 읽는 방법\n",
    "- 실시간 웹캠으로 모든 것을 동작시키는 방법\n",
    "\n",
    "## 📋 준비물\n",
    "- 컴퓨터에 웹캠이 있어야 합니다 (노트북 내장 카메라도 OK!)\n",
    "- 인터넷 연결 (AI 모델 파일을 다운로드해야 해요)\n",
    "\n",
    "## ⚠️ 주의사항\n",
    "- 코드를 실행할 때는 **순서대로** 실행해주세요!\n",
    "- 오류가 나면 당황하지 말고 천천히 다시 실행해보세요\n",
    "- 웹캠 권한을 요청하면 **허용**해주세요\n",
    "\n",
    "자, 그럼 시작해볼까요? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d826d35",
   "metadata": {},
   "source": [
    "# 1단계: 필요한 라이브러리 설치하기 📦\n",
    "\n",
    "먼저 우리가 사용할 도구들을 설치해야 합니다. 마치 요리하기 전에 재료를 준비하는 것과 같아요!\n",
    "\n",
    "아래 코드를 실행하면 다음과 같은 도구들이 설치됩니다:\n",
    "- **opencv-python**: 카메라와 이미지를 다루는 도구\n",
    "- **ultralytics**: YOLO AI 모델을 사용하는 도구\n",
    "- **numpy**: 수학 계산을 도와주는 도구\n",
    "- **dlib**: 얼굴 분석을 도와주는 도구\n",
    "\n",
    "⏰ **설치 시간**: 약 2-3분 정도 걸릴 수 있어요. 기다려주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리들을 설치합니다\n",
    "# 이 코드를 실행하면 자동으로 설치가 진행됩니다\n",
    "\n",
    "print(\"📦 라이브러리 설치를 시작합니다...\")\n",
    "print(\"☕ 잠깐 커피라도 마시며 기다려주세요!\")\n",
    "\n",
    "# pip install 명령어로 필요한 패키지들을 설치\n",
    "!pip install opencv-python ultralytics numpy\n",
    "\n",
    "print(\"\\n🎉 라이브러리 설치가 완료되었습니다!\")\n",
    "print(\"이제 다음 단계로 넘어가세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0885d3",
   "metadata": {},
   "source": [
    "## dlib 설치하기 🔧\n",
    "\n",
    "**dlib**은 조금 특별한 라이브러리예요. 설치가 어려울 수 있으니 여러 방법을 시도해볼게요!\n",
    "\n",
    "💡 **팁**: 만약 아래 코드에서 오류가 난다면, 다음 방법들을 시도해보세요:\n",
    "1. 먼저 아래 코드를 실행해보세요\n",
    "2. 오류가 나면 터미널에서 `conda install dlib` 시도\n",
    "3. 그래도 안 되면 `pip install dlib-binary` 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlib 설치를 시도합니다\n",
    "try:\n",
    "    print(\"🔧 dlib 설치를 시도합니다...\")\n",
    "    !pip install dlib\n",
    "    print(\"✅ dlib 설치 성공!\")\n",
    "except:\n",
    "    print(\"❌ dlib 설치 실패. 대안 방법을 시도합니다...\")\n",
    "    try:\n",
    "        !pip install dlib-binary\n",
    "        print(\"✅ dlib-binary 설치 성공!\")\n",
    "    except:\n",
    "        print(\"⚠️  dlib 설치에 문제가 있습니다.\")\n",
    "        print(\"   다음 방법을 시도해보세요:\")\n",
    "        print(\"   1. 터미널에서 'conda install dlib' 실행\")\n",
    "        print(\"   2. 또는 구글에서 'dlib 설치 방법' 검색\")\n",
    "\n",
    "print(\"\\n🎯 설치가 완료되면 다음 단계로 넘어가세요!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db44c74",
   "metadata": {},
   "source": [
    "# 2단계: 라이브러리 불러오기 및 테스트 🧪\n",
    "\n",
    "이제 설치한 도구들을 실제로 불러와서 잘 작동하는지 확인해봅시다!\n",
    "\n",
    "각 라이브러리가 무엇을 하는지 간단히 설명하면:\n",
    "- **cv2 (OpenCV)**: 카메라로 사진/영상을 찍고 처리\n",
    "- **YOLO**: 사진에서 사람을 찾아내는 AI\n",
    "- **numpy**: 숫자 계산을 빠르게 처리\n",
    "- **dlib**: 얼굴의 세밀한 부분들을 분석\n",
    "- **os, urllib, bz2**: 파일을 다운로드하고 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cf659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리들을 불러옵니다\n",
    "print(\"📚 라이브러리를 불러오는 중...\")\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(\"✅ OpenCV (cv2) - 카메라 도구 준비 완료!\")\n",
    "except ImportError:\n",
    "    print(\"❌ OpenCV 설치 실패. 위에서 설치를 다시 해주세요.\")\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print(\"✅ YOLO - 사람 감지 AI 준비 완료!\")\n",
    "except ImportError:\n",
    "    print(\"❌ YOLO 설치 실패. 위에서 설치를 다시 해주세요.\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"✅ NumPy - 수학 계산 도구 준비 완료!\")\n",
    "except ImportError:\n",
    "    print(\"❌ NumPy 설치 실패. 위에서 설치를 다시 해주세요.\")\n",
    "\n",
    "try:\n",
    "    import dlib\n",
    "    print(\"✅ dlib - 얼굴 분석 도구 준비 완료!\")\n",
    "except ImportError:\n",
    "    print(\"❌ dlib 설치 실패. 위에서 dlib 설치를 다시 해주세요.\")\n",
    "\n",
    "# 파일 관리용 라이브러리들\n",
    "import os\n",
    "import urllib.request\n",
    "import bz2\n",
    "\n",
    "print(\"\\n🎉 모든 라이브러리가 준비되었습니다!\")\n",
    "print(\"이제 AI 모델을 다운로드해봅시다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf33fe",
   "metadata": {},
   "source": [
    "# 3단계: AI 모델 다운로드하기 🤖\n",
    "\n",
    "이제 얼굴 분석을 위한 특별한 AI 모델을 다운로드해야 합니다.\n",
    "\n",
    "## 무엇을 다운로드하나요?\n",
    "**shape_predictor_68_face_landmarks.dat** 파일을 다운로드합니다.\n",
    "- 이 파일은 얼굴에서 눈, 코, 입, 턱선 등 68개의 중요한 점들을 찾아주는 AI 모델이에요\n",
    "- 파일 크기: 약 68MB\n",
    "- 한 번만 다운로드하면 계속 사용할 수 있어요\n",
    "\n",
    "⏰ **다운로드 시간**: 인터넷 속도에 따라 1-3분 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dlib_model():\n",
    "    \"\"\"\n",
    "    얼굴 분석을 위한 dlib 모델을 다운로드하는 함수\n",
    "    이미 파일이 있으면 다시 다운로드하지 않아요!\n",
    "    \"\"\"\n",
    "    model_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "    \n",
    "    # 이미 파일이 있는지 확인\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"✅ {model_path} 파일이 이미 있습니다!\")\n",
    "        print(\"다운로드를 건너뛰고 다음 단계로 넘어갑니다.\")\n",
    "        return True\n",
    "    \n",
    "    print(\"🔽 dlib 얼굴 랜드마크 모델을 다운로드하는 중...\")\n",
    "    print(\"   파일이 큰 편이니 조금 기다려주세요!\")\n",
    "    \n",
    "    url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
    "    \n",
    "    try:\n",
    "        # 1단계: 압축된 파일 다운로드\n",
    "        print(\"   📦 압축 파일 다운로드 중...\")\n",
    "        urllib.request.urlretrieve(url, 'shape_predictor_68_face_landmarks.dat.bz2')\n",
    "        \n",
    "        # 2단계: 압축 해제\n",
    "        print(\"   📂 압축 해제 중...\")\n",
    "        with bz2.BZ2File('shape_predictor_68_face_landmarks.dat.bz2', 'rb') as f:\n",
    "            with open(model_path, 'wb') as output:\n",
    "                output.write(f.read())\n",
    "        \n",
    "        # 3단계: 압축 파일 삭제 (정리)\n",
    "        os.remove('shape_predictor_68_face_landmarks.dat.bz2')\n",
    "        \n",
    "        print(\"✅ dlib 모델 다운로드 완료!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 다운로드 실패: {e}\")\n",
    "        print(\"\\n🔧 해결 방법:\")\n",
    "        print(\"   1. 인터넷 연결을 확인해주세요\")\n",
    "        print(\"   2. 또는 터미널에서 다음 명령어를 실행해보세요:\")\n",
    "        print(\"      wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "        print(\"      bunzip2 shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "        return False\n",
    "\n",
    "# 함수를 실행해서 모델을 다운로드합니다\n",
    "print(\"🚀 AI 모델 다운로드를 시작합니다!\")\n",
    "success = download_dlib_model()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n🎉 모든 준비가 완료되었습니다!\")\n",
    "    print(\"이제 얼굴 분석 함수를 만들어봅시다.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  모델 다운로드에 문제가 있습니다.\")\n",
    "    print(\"위의 해결 방법을 시도한 후 다시 실행해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e07cf5",
   "metadata": {},
   "source": [
    "# 4단계: 감정 분석 함수 만들기 😊😢😠😲\n",
    "\n",
    "이제 가장 재미있는 부분입니다! 얼굴 표정을 보고 감정을 알아내는 함수를 만들어봅시다.\n",
    "\n",
    "## 어떻게 감정을 알아낼까요?\n",
    "\n",
    "우리 함수는 얼굴의 **68개 중요 포인트**를 분석합니다:\n",
    "\n",
    "### 1. 입 모양 분석 👄\n",
    "- **웃음**: 입꼬리가 올라가고 입이 옆으로 길어짐\n",
    "- **슬픔**: 입꼬리가 아래로 내려감\n",
    "\n",
    "### 2. 눈 크기 분석 👀\n",
    "- **놀람**: 눈이 평소보다 크게 뜨임\n",
    "- **평상시**: 적당한 크기\n",
    "\n",
    "### 3. 눈썹 위치 분석 🤨\n",
    "- **화남**: 눈썹이 내려와서 찡그린 모양\n",
    "- **놀람**: 눈썹이 올라감\n",
    "\n",
    "### 감지할 수 있는 감정들:\n",
    "- 😊 **Happy** (행복) - 초록색으로 표시\n",
    "- 😢 **Sad** (슬픔) - 빨간색으로 표시  \n",
    "- 😠 **Angry** (화남) - 진한 빨간색으로 표시\n",
    "- 😲 **Surprised** (놀람) - 노란색으로 표시\n",
    "- 😐 **Neutral** (평상시) - 흰색으로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_facial_expression(landmarks):\n",
    "    \"\"\"\n",
    "    얼굴 랜드마크를 분석하여 감정을 판단하는 함수\n",
    "    \n",
    "    입력: landmarks (얼굴의 68개 중요 포인트)\n",
    "    출력: (감정이름, 색상, 신뢰도)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 🗣️ 입 관련 포인트들을 가져옵니다\n",
    "    mouth_left = landmarks.part(48)    # 입 왼쪽 끝\n",
    "    mouth_right = landmarks.part(54)   # 입 오른쪽 끝\n",
    "    mouth_top = landmarks.part(51)     # 입 위쪽\n",
    "    mouth_bottom = landmarks.part(57)  # 입 아래쪽\n",
    "    \n",
    "    # 👀 눈 관련 포인트들을 가져옵니다\n",
    "    left_eye_top = landmarks.part(37)     # 왼쪽 눈 위\n",
    "    left_eye_bottom = landmarks.part(41)  # 왼쪽 눈 아래\n",
    "    right_eye_top = landmarks.part(43)    # 오른쪽 눈 위\n",
    "    right_eye_bottom = landmarks.part(47) # 오른쪽 눈 아래\n",
    "    \n",
    "    # 🤨 눈썹 관련 포인트들을 분석합니다\n",
    "    left_eyebrow = np.mean([landmarks.part(i).y for i in range(17, 22)])   # 왼쪽 눈썹 평균 높이\n",
    "    right_eyebrow = np.mean([landmarks.part(i).y for i in range(22, 27)])  # 오른쪽 눈썹 평균 높이\n",
    "    \n",
    "    # 📊 특징들을 계산합니다\n",
    "    \n",
    "    # 1️⃣ 입의 가로세로 비율 (웃을 때는 입이 옆으로 길어져요)\n",
    "    mouth_width = abs(mouth_right.x - mouth_left.x)      # 입 너비\n",
    "    mouth_height = abs(mouth_top.y - mouth_bottom.y)     # 입 높이\n",
    "    mouth_ratio = mouth_height / mouth_width if mouth_width > 0 else 0\n",
    "    \n",
    "    # 2️⃣ 입꼬리 기울기 (웃으면 올라가고, 슬프면 내려가요)\n",
    "    mouth_curve = (mouth_left.y + mouth_right.y) / 2 - mouth_top.y\n",
    "    \n",
    "    # 3️⃣ 눈의 크기 (놀라면 눈이 커져요)\n",
    "    left_eye_height = abs(left_eye_top.y - left_eye_bottom.y)\n",
    "    right_eye_height = abs(right_eye_top.y - right_eye_bottom.y)\n",
    "    avg_eye_height = (left_eye_height + right_eye_height) / 2\n",
    "    \n",
    "    # 4️⃣ 눈썹과 눈 사이의 거리 (화나면 눈썹이 내려와요)\n",
    "    avg_eyebrow_height = (left_eyebrow + right_eyebrow) / 2\n",
    "    eye_center = (left_eye_top.y + right_eye_top.y) / 2\n",
    "    eyebrow_distance = eye_center - avg_eyebrow_height\n",
    "    \n",
    "    # 🎯 감정을 판단합니다!\n",
    "    emotion = \"Neutral\"         # 기본값: 평상시\n",
    "    color = (255, 255, 255)     # 기본 색상: 흰색\n",
    "    confidence = 0.5            # 기본 신뢰도: 50%\n",
    "    \n",
    "    # 조건에 따라 감정을 판별합니다\n",
    "    if mouth_curve < -5 and mouth_ratio < 0.5:  # 😊 웃음: 입꼬리 올라가고 입이 넓어짐\n",
    "        emotion = \"Happy\"\n",
    "        color = (0, 255, 0)  # 초록색\n",
    "        confidence = min(1.0, abs(mouth_curve) / 10)\n",
    "        \n",
    "    elif mouth_curve > 7:  # 😢 슬픔: 입꼬리 내려감\n",
    "        emotion = \"Sad\"\n",
    "        color = (255, 0, 0)  # 빨간색\n",
    "        confidence = min(1.0, mouth_curve / 10)\n",
    "        \n",
    "    elif avg_eye_height > 8 and eyebrow_distance > 15:  # 😲 놀람: 눈 크게 뜨고 눈썹 올라감\n",
    "        emotion = \"Surprised\"\n",
    "        color = (0, 255, 255)  # 노란색\n",
    "        confidence = min(1.0, avg_eye_height / 10)\n",
    "        \n",
    "    elif eyebrow_distance < 10:  # 😠 화남: 눈썹이 내려와서 찡그림\n",
    "        emotion = \"Angry\"\n",
    "        color = (0, 0, 255)  # 진한 빨간색\n",
    "        confidence = min(1.0, (15 - eyebrow_distance) / 10)\n",
    "    \n",
    "    return emotion, color, confidence\n",
    "\n",
    "print(\"✅ 감정 분석 함수가 준비되었습니다!\")\n",
    "print(\"이제 AI 모델들을 불러와봅시다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9c99d",
   "metadata": {},
   "source": [
    "# 5단계: AI 모델들 불러오기 🤖⚡\n",
    "\n",
    "이제 실제로 사용할 AI 모델들을 불러와봅시다!\n",
    "\n",
    "## 불러올 모델들:\n",
    "\n",
    "### 1. YOLO 모델 🎯\n",
    "- **역할**: 카메라 화면에서 사람을 찾아내기\n",
    "- **파일**: yolov8n.pt (처음 실행할 때 자동 다운로드)\n",
    "- **특징**: 매우 빠르고 정확함\n",
    "\n",
    "### 2. dlib 모델 🔍\n",
    "- **역할**: 얼굴에서 정확한 68개 포인트 찾기\n",
    "- **파일**: shape_predictor_68_face_landmarks.dat (위에서 다운로드함)\n",
    "- **특징**: 얼굴 외곽선과 표정 분석에 최적화\n",
    "\n",
    "⏰ **로딩 시간**: YOLO 모델이 처음이면 약 1-2분, 이후엔 몇 초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 AI 모델들을 불러오는 중...\")\n",
    "print(\"처음 실행이면 YOLO 모델 다운로드로 시간이 걸릴 수 있어요!\")\n",
    "\n",
    "try:\n",
    "    # 1️⃣ YOLO 모델 로드 (사람 감지용)\n",
    "    print(\"\\n🎯 YOLO 모델 로딩 중...\")\n",
    "    yolo_model = YOLO('yolov8n.pt')  # nano 버전 (가장 빠름)\n",
    "    print(\"✅ YOLO 모델 로드 완료! (사람 감지 준비됨)\")\n",
    "    \n",
    "    # 2️⃣ dlib 얼굴 감지기 준비\n",
    "    print(\"\\n🔍 dlib 얼굴 감지기 준비 중...\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    print(\"✅ dlib 얼굴 감지기 준비 완료!\")\n",
    "    \n",
    "    # 3️⃣ dlib 랜드마크 예측기 로드\n",
    "    print(\"\\n📍 dlib 랜드마크 예측기 로딩 중...\")\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    print(\"✅ dlib 랜드마크 예측기 로드 완료! (68개 포인트 분석 준비됨)\")\n",
    "    \n",
    "    print(\"\\n🎉 모든 AI 모델이 준비되었습니다!\")\n",
    "    print(\"이제 웹캠으로 실시간 감정 인식을 시작할 수 있어요!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 모델 로딩 중 오류 발생: {e}\")\n",
    "    print(\"\\n🔧 해결 방법:\")\n",
    "    print(\"1. 위의 설치 단계들을 다시 확인해주세요\")\n",
    "    print(\"2. 특히 dlib 모델 파일이 제대로 다운로드되었는지 확인\")\n",
    "    print(\"3. 인터넷 연결 상태 확인\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559187b",
   "metadata": {},
   "source": [
    "# 6단계: 실시간 감정 인식 실행하기! 🎥✨\n",
    "\n",
    "드디어 모든 준비가 끝났습니다! 이제 웹캠을 켜서 실시간으로 감정을 인식해봅시다.\n",
    "\n",
    "## 🎮 사용법:\n",
    "1. 아래 코드를 실행하면 웹캠 창이 열립니다\n",
    "2. 카메라 앞에 얼굴을 보여주세요\n",
    "3. 다양한 표정을 지어보세요! (웃기, 슬퍼하기, 화내기, 놀라기)\n",
    "4. 얼굴 주변에 색깔이 있는 외곽선이 나타나고 감정이 표시됩니다\n",
    "5. **'q' 키를 누르면 종료**됩니다\n",
    "\n",
    "## 🌈 색깔 의미:\n",
    "- **초록색** 😊 = Happy (행복)\n",
    "- **빨간색** 😢 = Sad (슬픔)\n",
    "- **진한 빨간색** 😠 = Angry (화남)\n",
    "- **노란색** 😲 = Surprised (놀람)\n",
    "- **흰색** 😐 = Neutral (평상시)\n",
    "\n",
    "## ⚠️ 주의사항:\n",
    "- 웹캠 접근 권한을 허용해주세요\n",
    "- 밝은 곳에서 촬영하면 더 정확해요\n",
    "- 얼굴이 화면에 잘 보이도록 해주세요\n",
    "- 종료할 때는 반드시 **'q' 키**를 누르세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_emotion_detection():\n",
    "    \"\"\"\n",
    "    실시간 감정 인식을 시작하는 메인 함수\n",
    "    \"\"\"\n",
    "    print(\"🎥 웹캠을 초기화하는 중...\")\n",
    "    \n",
    "    # 웹캠 연결 (0번은 기본 카메라)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ 카메라를 열 수 없습니다!\")\n",
    "        print(\"🔧 해결 방법:\")\n",
    "        print(\"   1. 다른 프로그램에서 카메라를 사용하고 있는지 확인\")\n",
    "        print(\"   2. 웹캠이 제대로 연결되어 있는지 확인\")\n",
    "        print(\"   3. 카메라 권한이 허용되어 있는지 확인\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n🎉 감정 인식이 시작되었습니다!\")\n",
    "    print(\"📹 웹캠 창이 열립니다...\")\n",
    "    print(\"🎭 다양한 표정을 지어보세요!\")\n",
    "    print(\"⌨️  'q' 키를 누르면 종료됩니다.\")\n",
    "    print(\"\\n💡 팁: 밝은 곳에서 얼굴이 잘 보이도록 해주세요!\")\n",
    "    \n",
    "    while True:\n",
    "        # 카메라에서 한 프레임 읽기\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ 카메라에서 영상을 읽을 수 없습니다.\")\n",
    "            break\n",
    "        \n",
    "        # YOLO로 사람 감지\n",
    "        yolo_results = yolo_model(frame, verbose=False)\n",
    "        \n",
    "        # 감지된 사람들을 하나씩 처리\n",
    "        for result in yolo_results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    class_id = int(box.cls[0])\n",
    "                    confidence = float(box.conf[0])\n",
    "                    \n",
    "                    # 사람이 감지되고 신뢰도가 50% 이상인 경우\n",
    "                    if class_id == 0 and confidence > 0.5:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        \n",
    "                        # 사람이 있는 영역만 추출해서 얼굴 찾기\n",
    "                        person_roi = frame[y1:y2, x1:x2]\n",
    "                        gray_roi = cv2.cvtColor(person_roi, cv2.COLOR_BGR2GRAY)\n",
    "                        \n",
    "                        # dlib으로 얼굴 감지\n",
    "                        faces_dlib = detector(gray_roi)\n",
    "                        \n",
    "                        # 감지된 얼굴마다 처리\n",
    "                        for face in faces_dlib:\n",
    "                            # 68개 랜드마크 포인트 찾기\n",
    "                            landmarks = predictor(gray_roi, face)\n",
    "                            \n",
    "                            # 🎭 감정 분석하기\n",
    "                            emotion, emotion_color, emotion_confidence = analyze_facial_expression(landmarks)\n",
    "                            \n",
    "                            # 얼굴 외곽선 그리기 준비\n",
    "                            face_outline = []\n",
    "                            \n",
    "                            # 턱선 포인트들 (0~16번)\n",
    "                            for i in range(0, 17):\n",
    "                                x = landmarks.part(i).x + x1\n",
    "                                y = landmarks.part(i).y + y1\n",
    "                                face_outline.append([x, y])\n",
    "                            \n",
    "                            # 이마 부분 추가 (눈썹 위쪽)\n",
    "                            forehead_points = []\n",
    "                            for i in range(17, 27):  # 눈썹 포인트들\n",
    "                                x = landmarks.part(i).x + x1\n",
    "                                y = landmarks.part(i).y + y1 - 20  # 이마 높이 조정\n",
    "                                forehead_points.append([x, y])\n",
    "                            \n",
    "                            # 이마 포인트를 역순으로 추가해서 닫힌 모양 만들기\n",
    "                            forehead_points.reverse()\n",
    "                            face_outline.extend(forehead_points)\n",
    "                            \n",
    "                            # numpy 배열로 변환\n",
    "                            face_outline = np.array(face_outline, np.int32)\n",
    "                            \n",
    "                            # 🎨 감정에 따른 색상으로 얼굴 외곽선 그리기\n",
    "                            cv2.polylines(frame, [face_outline], True, emotion_color, 3)\n",
    "                            \n",
    "                            # 📝 감정 정보 텍스트로 표시\n",
    "                            face_x = face.left() + x1\n",
    "                            face_y = face.top() + y1\n",
    "                            \n",
    "                            cv2.putText(frame, f'{emotion} ({emotion_confidence:.2f})', \n",
    "                                      (face_x, face_y - 40), \n",
    "                                      cv2.FONT_HERSHEY_SIMPLEX, 0.8, emotion_color, 2)\n",
    "        \n",
    "        # 화면에 결과 보여주기\n",
    "        cv2.imshow('🎭 실시간 감정 인식 - q키로 종료', frame)\n",
    "        \n",
    "        # 'q' 키를 누르면 종료\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # 정리 작업\n",
    "    cap.release()           # 카메라 해제\n",
    "    cv2.destroyAllWindows() # 모든 창 닫기\n",
    "    print(\"\\n👋 감정 인식을 종료했습니다. 수고하셨어요!\")\n",
    "\n",
    "# 🚀 실행하기!\n",
    "print(\"🎬 실시간 감정 인식을 시작합니다!\")\n",
    "print(\"잠깐, 준비 중...\")\n",
    "\n",
    "try:\n",
    "    start_emotion_detection()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️  사용자가 중단했습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 오류가 발생했습니다: {e}\")\n",
    "    print(\"🔧 해결 방법을 위해 위의 단계들을 다시 확인해보세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0581893",
   "metadata": {},
   "source": [
    "# 🎉 축하합니다! 완료했어요!\n",
    "\n",
    "정말 고생하셨습니다! 여러분은 방금 **인공지능을 활용한 실시간 감정 인식 시스템**을 만들어냈어요! 🤖✨\n",
    "\n",
    "## 🏆 무엇을 배웠나요?\n",
    "\n",
    "1. **AI 라이브러리 사용법**: OpenCV, YOLO, dlib 같은 전문적인 도구들\n",
    "2. **컴퓨터 비전**: 카메라로 실시간 영상 처리하는 방법\n",
    "3. **얼굴 분석**: 68개 랜드마크 포인트로 정확한 얼굴 분석\n",
    "4. **감정 인식**: 수학적 계산으로 표정에서 감정 읽기\n",
    "5. **실시간 처리**: 초당 여러 프레임을 빠르게 분석하는 기술\n",
    "\n",
    "## 🚀 다음 단계로 발전시켜보세요!\n",
    "\n",
    "### 1. 더 많은 감정 추가하기\n",
    "```python\n",
    "# 예시: 윙크 감지 추가\n",
    "if left_eye_height < 3 and right_eye_height > 5:\n",
    "    emotion = \"Winking\"\n",
    "    color = (255, 0, 255)  # 보라색\n",
    "```\n",
    "\n",
    "### 2. 감정 기록하기\n",
    "- 시간별로 감정 변화를 그래프로 만들어보세요\n",
    "- 하루 동안 어떤 감정이 가장 많았는지 분석해보세요\n",
    "\n",
    "### 3. 여러 사람 동시 감지\n",
    "- 친구들과 함께 사용해서 누가 더 행복한지 겨뤄보세요!\n",
    "\n",
    "### 4. 음성 추가\n",
    "```python\n",
    "# 감정에 따라 다른 소리 재생\n",
    "if emotion == \"Happy\":\n",
    "    print(\"🎵 행복한 음악 재생!\")\n",
    "```\n",
    "\n",
    "## 📚 더 공부하고 싶다면?\n",
    "\n",
    "- **컴퓨터 비전**: OpenCV 공식 튜토리얼\n",
    "- **딥러닝**: TensorFlow, PyTorch 배우기\n",
    "- **AI 윤리**: AI가 사회에 미치는 영향 생각해보기\n",
    "- **로봇공학**: 실제 로봇에 이 기술 적용해보기\n",
    "\n",
    "## 💡 프로젝트 아이디어\n",
    "\n",
    "1. **스마트 미러**: 아침에 거울을 보면 오늘의 기분을 알려주는 시스템\n",
    "2. **수업 집중도 측정**: 학생들의 표정으로 수업 이해도 파악\n",
    "3. **반려동물 감정 인식**: 강아지나 고양이 표정도 읽어보기\n",
    "4. **게임 컨트롤러**: 표정으로 게임 캐릭터 조종하기\n",
    "\n",
    "---\n",
    "\n",
    "**🎓 여러분은 이제 AI 개발자의 첫 걸음을 뗐습니다!**\n",
    "\n",
    "이 경험을 바탕으로 더 멋진 AI 프로젝트들을 만들어보세요. 실패를 두려워하지 말고, 계속 도전하고 실험해보세요! 🌟\n",
    "\n",
    "**Keep coding and keep learning! 화이팅! 💪**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
